{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unauthorized-infrastructure",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "In an ever-competitive job market, finding employment can be quite difficult. Finding a suitable employment opportunity can become quite time consuming for job seekers with a medium sized posting having an average of 550 words (Jennifer Gladstone, 2017). On average, it takes approximately 15 applications to land a job interview, and around 10 interviews to secure a single job offer. This means that an applicant would need to apply for 150 job positions before receiving a single job offer (Chakrabarti et al., 2019). If each job listing takes three minutes to read, a job seeker would need to spend 5 hours reading listings, plus additional time to complete the employerâ€™s application process.\n",
    "\n",
    "Currently, job seekers must scour through multiple sites worth of job postings and read through entire the entire listings in order to determine if they possess the required skill set whilst also ensuring the day-to-day tasks they will be undertaking are suitable for their career aspirations.\n",
    "\n",
    "Job seekers would benefit significantly from a central repository of job listings, with each listing containing a summarization, that is restricted to a handful of sentences, and metadata tags of the required skills. This repository would streamline the job application process and enable applicants to apply for jobs at a notably faster rate by reducing the amount of time spent reading applications and filtering out listings that require skills the candidate does not possess. \n",
    "\n",
    "A web-crawler could be employed to scrape through multiple sites that contain job listings, extracting the job title, job position and job description from each article. By utilising a web crawler that crawls multiple sites, the process of job listing collection can be automated and enable the central repository to contain a large quantity of employment opportunities. \n",
    "\n",
    "By making use of Natural Language Processing tasks, the central repository can provide skill metadata tags and listing summarizations. For this use case, two tasks will be employed:\n",
    "- Summarisation through the use of extraction-based summarisation NLP techniques\n",
    "- Skill keyword extraction through the use of a Long Short-Term Memory (LSTM) deep learning network and word embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-plymouth",
   "metadata": {},
   "source": [
    "## References\n",
    "Jennifer Gladstone, J. G. (2017, September 22). 15 Science-backed Tips for Writing Job Descriptions. Undercover Recruiter. https://theundercoverrecruiter.com/tips-writing-job-descriptions/\n",
    "\n",
    "\n",
    "Chakrabarti, K., Chakrabarti, K., & Chakrabarti, V. A. P. B. K. (2019, April 6). How Long Does It Take to Get a Job in America Today? 84.3 Days for HR. . .. TalentWorks. https://talent.works/2017/09/22/how-long-does-it-take-to-get-a-job-60-days-if-youre-in-hr-or-sales/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
